---
title: "Data challenge & SHS: Logistic regression and linear model"
author:
  - Julie Josse, Gaël Varoquaux, and Bénédicte Colnet
date: "February 2021"
output:
  pdf_document:
    toc: yes
    toc_depth: 3
  html_document:
    number_sections: no
    toc: yes
    toc_depth: 3
keywords: linear model; logistic regression; prediction; ROC
abstract: |
  In this tutorial, you will perform a logistic regression with `R`. This is the first exercice and we will do it together in class. At the end you can find an exercice with a simple linear regression you should be able to do alone at home (solutions will be given later).
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

 *Credits for this lab*: **An Introduction to Statistical Learning: With Applications in R** book from Garet James, Daniela Witten, Trevor Hastie, Robert Tibshirani (in particular for the exercice on Logistic Regression and stock market)
 The exercice on linear model comes from Imke Mayer's labs. Thanks to them.


# Logistic regression: stock market data

In this part we use the `Smarket` data, which is part of the `ISLR` library. This data set consists of percentage returns for the S&P 500 stock index over 1250 days, from the beginning of 2001 until the end of 2005.


The S&P 500,or simply the S&P, is a stock market index that measures the stock performance of 500 large companies listed on stock exchanges in the United States. It is one of the most commonly followed equity indices. (I guess we can compare it with the French CAC 40)

Therefore you have 1250 observations on the following 9 variables.

`Year`
The year that the observation was recorded

`Lag1`
Percentage return for previous day

`Lag2`
Percentage return for 2 days previous

`Lag3`
Percentage return for 3 days previous

`Lag4`
Percentage return for 4 days previous

`Lag5`
Percentage return for 5 days previous

`Volume`
The number of shares traded

`Today`
The percentage return on the date in question

`Direction`
A factor with levels Down and Up indicating whether the market had a positive or negative return on a given day


## Question 1: Data exploration

Load the library `ISLR` and inspect the data set. Do you see a link between returns? For example you can also look at correlation.
What can you say on the volume of shares traded over year?

**Solution**

```{r}
library(ISLR)
Smarket <- Smarket
names(Smarket)
summary(Smarket)
```


```{r}
cor(Smarket[,-9])
```
There appears to be little correlation between today’s returns and previous days’ returns.
We can observe a correlation on the `Year` and `Volume`.

```{r}
library(ggplot2)
ggplot(Smarket, aes(x = as.numeric(row.names(Smarket)), y = Volume, color = Direction)) +
  geom_point() +
  theme_classic() +
  xlab("Index")
```

**End of solution**

## Question 2: Logistic regression

Fit a logistic regression model in order to predict `Direction` using all the other available variables. 


For this you can use `glm()`, a class of models that includes logistic regression.

Interpret the result. What is the coefficient that is the most linked to the outcome according to this model?



**Solution**
```{r}
glm.fit = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Smarket, family = binomial)
summary(glm.fit)
```

The smallest p-value here is associated with `Lag1`. The negative coefficient
for this predictor suggests that if the market had a positive return yesterday, then it is less likely to go up today. However, at a value of 0.15, the p-value is still relatively large, and so there is no clear evidence of a real association between `Lag1` and `Direction`.


Be careful to look at which variable is the 1 or the 0. `R` automatically creates so-called dummy variables you can inspect with `contrasts()`.
```{r}
contrasts(Smarket$Direction)
```


**End of solution**

## Question 3: Prediction

You can use the `predict()` function to perform prediction that the market will go up given other values. Remember that it corresponds to the quantity:

$$\mathbb{P}(Direction = Up | Lag1, \dots, Volume)$$

If no data set is supplied to the `predict()` function, then the probabilities are computed for the training data used to fit the logistic regression model.

After doing this prediction, you will have the probability of having $Y=1$. Now, create a confusion matrix with the function `table()` to determine how many observations were correctly or incorrectly classified. 

Conclude on this model efficacy.
What would you do to better assess this model efficacy?

**Solution**

```{r}
glm.probs <- predict(glm.fit, type = "response")

Smarket$probs <- glm.probs


ggplot(Smarket, aes(y = probs, x = Direction, group = Direction)) +
  geom_boxplot() +
  theme_bw()
  
```

The following two commands create a vector of class predictions based on whether the predicted probability of a market increase is greater than or less than 0.5.
```{r}
glm.pred = rep(0, 1250)
```


```{r}
glm.pred[glm.probs > .5] = 1
table(glm.pred, Smarket$Direction)
```
The diagonal elements of the confusion matrix indicate correct predictions, while the off-diagonals represent incorrect predictions. Hence our model correctly predicted that the market would go up on 507 days and that it would go down on 145 days, for a total of 507 + 145 = 652 correct predictions. Logistic regression correctly predicted the movement of the market 52.2% of the time.

This value is a little better than the random classifier. Remember that without knowing anything on your data, when you want to classify something you can still use a random classifier that will say 0 or 1 at each new guess without any **a priori** on the data. You can notice that the current performance is very bad because 52.2% is our training error, which is clearly optimistic (you will see this with Gaël class and the MOOC on Scikit Learn).

The next part of the solution is a bonus part. You can look at it if you want.
To implement this strategy, we will first create a vector corresponding to the observations from 2001 through 2004. We will then use this vector to create a held out data set of observations from 2005.

```{r}
test = Smarket[Smarket$Year == 2005,]
glm.fit = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, family=binomial, data = Smarket[Smarket$Year <2005, ])
glm.probs = predict(glm.fit, newdata = test, type = "response")
glm.pred = rep(0, nrow(test))
glm.pred[glm.probs >.5]=1
table(glm.pred, test$Direction)
```
The results are rather disappointing: the test error rate is 48%, which is worse than random guessing! Note that if it was possible to accurately predicts day return with previous days, it would be easier to be a trader ;) !

**End of solution**

## Question 4: ROC curves

The prediction performed before is by default made with a cutoff at 0.5. But maybe another threshold would help to have a better performance. Using the library `pROC`, screen for the best cutoff. The function you will use is the function `roc()`.

**Solution**

```{r}
library(pROC)
glm.fit = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Smarket, family =binomial)
glm.probs <- predict(glm.fit, type = "response")
test_roc = roc(Smarket$Direction ~ glm.probs, plot = TRUE, print.auc = TRUE)
```

```{r}
as.numeric(test_roc$auc)
```
A good model will have a high AUC, that is as often as possible a high sensitivity and specificity.

**End of solution**

# Exploratory data analysis and  simple regression

## The database

The data are stored in the file 'bea-2006.csv'. It contains information about the economies of the 366 metropolitan statistical areas" (cities) of the US in 2006. In particular, it lists, for each city:

- the population, 
- the total value of all goods and services produced for sale in the city that year per person (per capita gross metropolitan product“, pcgmp),
- and the share of economic output coming from *four* selected industries.

## Question 1: load data

Load the data and perform a summary analysis.


*Solution 1*
```{r}
data <- read.csv('bea-2006.csv', row.names=1)
```

```{r}
summary(data)
```


*End of solution 1*


## Question 2: data exploration

Produce histogram of population (density and the histogram with "bar") and the box plot of the pgmp column.

Tips: Don't hesitate to do an histogram without the outliers.

*Solution 2*

```{r, warning = FALSE, message = FALSE}
library(ggplot2)
ggplot(data, aes(x = pop)) +
 geom_histogram(aes(y=..density..), alpha=0.3, 
                position="identity", binwidth = 100000, fill = "steelblue", color = "black")+
 geom_density(alpha=0.9)
  theme_bw()
```

Note that with this plot we can see that outliers seem to be present. You can always use a boxplot to have evidence of it.

```{r}
ggplot(data, aes(y = pop)) +
  geom_boxplot(outlier.colour = "red") +
  theme_bw()
```

You can then reproduce the previous plot without the outliers:

```{r}
ggplot(data[data$pop < 5000000 ,], aes(x = pop)) +
 geom_histogram(aes(y=..density..), alpha=0.3, 
                position="identity", binwidth = 100000, fill = "steelblue", color = "black")+
 geom_density(alpha=0.9)
  theme_bw()
```



```{r}
ggplot(data, aes(x = log(pop))) +
  geom_histogram(bins = 50, alpha = 0.9, fill = "lightblue") +
  theme_bw()
```


```{r}
ggplot(data, aes(y = pcgmp)) +
  geom_boxplot() +
  theme_bw()
```


*End of solution 2*

## Question 3: GMP and population

Make a bivariate plot for per-capita GMP as a function of population. Describe the relationship in words. You can also try with $log(pop)$.

*Solution 3*

```{r}
ggplot(data, aes(x = pop, y = pcgmp)) +
  geom_point() +
  theme_bw()

ggplot(data, aes(x = log(pop), y = pcgmp)) +
  geom_point() +
  theme_bw()
```


*End of solution 3*



## Question 4: simple linear model

Considering your previous plot, run the `lm()` function on the data and add the regression to the previous plot. Will you use `pop` or `log(pop)`? (would the last one still be a linear model?) 

You can comment the result.

*Solution 4*


```{r}
model = lm(pcgmp~log(pop), data = data)
print(model$coefficients)
```


```{r}
ggplot(data, aes(x = log(pop), y = pcgmp)) +
  geom_point() +
  theme_bw() + 
  geom_abline(slope = model$coefficients[[2]], intercept = model$coefficients[[1]])
```

The fit does not seem to be a good one.

```{r}
summary(model)
```

Note that it is not easy to interpret `log(pop)` in comparison with `pop`.

*End of solution 4*

## Question 5

Bonus question: could you do `log(pcgmp)` as a linear function of `pop` (or `log(pop)`)?

*Solution 5*
This would be wrong! Because it implies a multiplication. Here to keep the model linear it should be $log(Y) = \beta X *\varepsilon$
*End of solution 5*

