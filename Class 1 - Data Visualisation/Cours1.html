<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Class 1: Data visualization and exploration</title>
    <meta charset="utf-8" />
    <meta name="author" content="Julie Josse, Ga√´l Varoquaux, and B√©n√©dicte Colnet" />
    <script src="Cours1_files/header-attrs-2.6/header-attrs.js"></script>
    <link href="Cours1_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="Cours1_files/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <link href="Cours1_files/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
    <script src="Cours1_files/kePrint-0.0.1/kePrint.js"></script>
    <link href="Cours1_files/lightable-0.0.1/lightable.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Class 1: Data visualization and exploration
### Julie Josse, Ga√´l Varoquaux, and B√©n√©dicte Colnet
### Lundi 18 Janvier 2021

---




# Purpose of this class


At the end of this class you will be able to perform a ***data exploration*** in `R`. 

--

This term first appeared in a book from John Tukey (1977):

*"Practice of inspecting, and exploring your data, before stating hypotheses, fitting predictors, and other more ambitious inferential goals. It typically includes the computation of simple summary statistics which capture some property of interest in the data, and visualization."*

Note that this is *assumption-free*.

--

It includes being able to:

- Load and preview data;
- Visualize data;
- Compute basic statistical metrics such as mean, median, correlation coefficient. These are called **point estimates**;
- Understand what is behind a confidence interval;
- Run standard statistical tests;
- Be aware of typical bias (Simpson paradox);
- Understand what a p-value means.

---
# Notations



We will (try to!) have as less as possible the need of mathematical formula for this class. 

--

The core material in statistics and machine learning is *data* (and it can be dirty data!):
&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; WindDirection &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; maxO3 &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; T9 &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Ne9 &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Vx15 &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; North &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 87 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 15.6 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.6946 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; North &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 82 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; NA &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -3.0000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; East &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 92 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 15.3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.5209 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; North &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 114 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 16.2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.1736 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

--

This is the minimum notation you should keep in mind:

- `\(n\)` is the number of observation in a data set
- `\(p\)` is the number of covariates (= features = caracteristics) by observation 
- `\(X\)` is usually a matrix of size `\(n\)` x `\(p\)` (you can also find `\(Y\)`, a vector of size `\(n\)` x `\(1\)`, being the variable to explain). A realization of the variable can be denoted `\(x\)`
- `\(i\)` denotes the `\(i^{th}\)` observations, for example `\(x_i\)` is the `\(i^{th}\)` element of a sample.

---
# Typical statistical quantities


### Empirical mean

If we consider a random variable `\(X\)`, we would like to define its average. It can also be seen as a weighted sum of the possible values that `\(X\)` can take.

--
Mathematically it is written:

`$$\bar{x}=\frac{1}{n} \sum_{i=1}^{n} x_{i}$$`

--

### Standard deviation

.pull-left[
It measures how the spread in the data.
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="./img/sd.png" alt="From sixsigmadsi.com" width="80%" /&gt;
&lt;p class="caption"&gt;From sixsigmadsi.com&lt;/p&gt;
&lt;/div&gt;
]
.pull-right[

Using the previous notations for the expected value it gives:

`$$\sigma=\sqrt{V}=\sqrt{\frac{1}{n} \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}}$$`
]
---
# Why can't we just use Excel? ü§î

These notations are the very basics for this class, and now we start a real data analysis using `R`, and not `excel`. Why?

--

- Not reproducible üîÅ
- Hard to merge different data set ü§ù
- To clean data is fastidious üßπ
- Not designed for complex visualization üé®
- It is not free üëõ
- And it can be super slow üê¢


&lt;img src="./img/slow.png" width="20%" style="display: block; margin: auto;" /&gt;

--

For this class we use air pollution data, the data are stored in `ozoneNA.csv`. 

After the class you should be able to reproduce all the commands that will be shown in this class.


---
# How to load data?

(Classical) data are generally contained within a file in which the individuals are presented in rows and the variables in columns. 

--

In `R` the data are stored in an object called a `data.frame`.


--

The classical way to read a data file is to use the function `read.table` or `read.csv`.


```r
ozone &lt;- read.table("ozoneNA.csv", header = TRUE, sep = ",", row.names = 1) 
```

--

Here, our data are stored in an `R` object called `ozone`. You can give the name you want to your objects üë∂, but try to be consistent and kind with an external reader.

--

Make sure you understand each parameter (`header`, `sep`, `row.names`) of the function `read.table()`. When you don't know how to use a function, you can do `?read.table()` to access the documentation.

---

# Inspect your object

- Let's look at the first 3 rows of `ozone`. (you can also do `head(ozone)`)



```r
ozone[1:3, 1:10] # show first 3 rows and 10 first columns
```

```
##          maxO3   T9  T12  T15 Ne9 Ne12 Ne15     Vx9    Vx12    Vx15
## 20010601    87 15.6 18.5   NA   4    4    8  0.6946 -1.7101 -0.6946
## 20010602    82   NA   NA   NA   5    5    7 -4.3301 -4.0000 -3.0000
## 20010603    92 15.3 17.6 19.5   2   NA   NA  2.9544      NA  0.5209
```

--

- To access one of the variable, you can use the `$` operator, for example with the temperature at 9am.


```r
ozone$T9[1:10] # only the first 10
```

```
##  [1] 15.6   NA 15.3 16.2   NA 17.7 16.8 14.9 16.1 18.3
```

--

Note that this is equivalent as `ozone[, "T9"]` or `ozone[, 2]`.


---

# Univariate analysis


Here we have at our disposal 112 observations collected during the summer of 2001 in Rennes. The available variables are

- maxO3 (maximum daily ozone)
- maxO3v (maximum daily ozone the previous day)
- T12 (temperature at midday)
- T9
- T15 (Temp at 3pm)
- Vx12 (projection of the wind speed vector on the east-west axis at midday)
- Vx9 and Vx15 as well as the Nebulosity (cloud) Ne9, Ne12, Ne15

--

Before any analysis an important point is to visualize the data. 
For example you can print the dimension of the dataframe stored in the object `ozone`.


```r
dim(ozone) 
```

```
## [1] 112  12
```

---
# Univariate analysis


`summary()` details the data type of each column.

```r
summary(ozone[, 8:12]) # 5 last columns so that it fits in the slide but you can launch everything doing simply summary(ozone)
```

```
##       Vx9               Vx12              Vx15            maxO3v       WindDirection
##  Min.   :-7.8785   Min.   :-7.8785   Min.   :-9.000   Min.   : 42.00   East :10     
##  1st Qu.:-3.0000   1st Qu.:-3.6941   1st Qu.:-3.759   1st Qu.: 70.00   North:31     
##  Median :-0.8671   Median :-1.9284   Median :-1.710   Median : 82.50   South:21     
##  Mean   :-1.0958   Mean   :-1.6853   Mean   :-1.830   Mean   : 89.39   West :50     
##  3rd Qu.: 0.6919   3rd Qu.:-0.1302   3rd Qu.: 0.000   3rd Qu.:101.00                
##  Max.   : 5.1962   Max.   : 6.5778   Max.   : 3.830   Max.   :166.00                
##  NA's   :18        NA's   :10        NA's   :21       NA's   :12
```

--

Can you already see difference in variable type? üïµ


---
# Useful commands


All the column names can be retrieved with the command `names()`.


```r
names(ozone)
```

```
##  [1] "maxO3"         "T9"            "T12"           "T15"           "Ne9"           "Ne12"         
##  [7] "Ne15"          "Vx9"           "Vx12"          "Vx15"          "maxO3v"        "WindDirection"
```

Basic statistics can be computed:


```r
mean(ozone$maxO3, na.rm = TRUE)
```

```
## [1] 91.23958
```

--

Note that the option `na.rm = TRUE` is necessary because the data contain missing value. If not the output will be a missing value.

--

All the basics statistics are implemented such as `sd()`, `min()`, `median()`, or `max()`.
---

# Two important data types

The data can be of two types: 

- **Qualitatives** 

  *For example colors, or gender.*

- **Quantitatives**

  *For exemple a salary, or heigth.*

--

‚ö†Ô∏è You have to be careful, whenever you replace colors by numbers (for example red with 0 and blue with 1), the data type will be set to numerical (so quantitative) and the computer can do operation on it. For example blue will be considered bigger than red, which has no meaning.

--

üí° The command `summary()` already allows you to observe your data type, another command is possible with `str()`.

--

üñç You can change the type of your data from quantitative to qualitative using the command `factor()`.
---


# Illustration of the data type on Ozone

Inspect qualitative data is basically counting occurences:


```r
table(ozone$WindDirection)
```

```
## 
##  East North South  West 
##    10    31    21    50
```


--

You can do operation on quantitative variables:

```r
test &lt;- ozone$maxO3 + ozone$T9
mean(test, na.rm = TRUE)
```

```
## [1] 109.7714
```

--

By the way, you can create a column composed by operation on other column such as `ozone$my_new_column &lt;- ozone$maxO3 + ozone$T9 * ozone$T12`.

---
# Visualization in R

Remember you can draw very beautiful plots in `R`.


In this class we suggest you to use:


- `ggplot2` for static plots;

- `gganimate` if you want to do animated plots from static `ggplot`;

- `Shiny` to host dynamic visualization of your data (really great to share  visualization of a big data base within a team or for external communication). 


--

Before we detail how to do it, here are example to show you a part of what  is possible!


---
# Example 1 : time series

&lt;img src="Cours1_files/figure-html/unnamed-chunk-13-1.png" style="display: block; margin: auto;" /&gt;

---
# Example 2 : scatter plot

&lt;img src="Cours1_files/figure-html/unnamed-chunk-14-1.png" style="display: block; margin: auto;" /&gt;

---
# Example 3 : population pyramid
&lt;img src="Cours1_files/figure-html/unnamed-chunk-15-1.png" style="display: block; margin: auto;" /&gt;

---
# Example 4: heat maps
&lt;img src="Cours1_files/figure-html/unnamed-chunk-16-1.png" style="display: block; margin: auto;" /&gt;

---
# Animated plots

These are data linking GDP per capita and life expectancy over years and for different countries. We may want to animate it over time.
&lt;img src="Cours1_files/figure-html/unnamed-chunk-17-1.png" style="display: block; margin: auto;" /&gt;

---
# Animated plots

These are data linking GDP per capita and life expectancy over years and for different countries. We may want to animate it over time.

```
## 
Frame 1 (1%)
Frame 2 (2%)
Frame 3 (3%)
Frame 4 (4%)
Frame 5 (5%)
Frame 6 (6%)
Frame 7 (7%)
Frame 8 (8%)
Frame 9 (9%)
Frame 10 (10%)
Frame 11 (11%)
Frame 12 (12%)
Frame 13 (13%)
Frame 14 (14%)
Frame 15 (15%)
Frame 16 (16%)
Frame 17 (17%)
Frame 18 (18%)
Frame 19 (19%)
Frame 20 (20%)
Frame 21 (21%)
Frame 22 (22%)
Frame 23 (23%)
Frame 24 (24%)
Frame 25 (25%)
Frame 26 (26%)
Frame 27 (27%)
Frame 28 (28%)
Frame 29 (29%)
Frame 30 (30%)
Frame 31 (31%)
Frame 32 (32%)
Frame 33 (33%)
Frame 34 (34%)
Frame 35 (35%)
Frame 36 (36%)
Frame 37 (37%)
Frame 38 (38%)
Frame 39 (39%)
Frame 40 (40%)
Frame 41 (41%)
Frame 42 (42%)
Frame 43 (43%)
Frame 44 (44%)
Frame 45 (45%)
Frame 46 (46%)
Frame 47 (47%)
Frame 48 (48%)
Frame 49 (49%)
Frame 50 (50%)
Frame 51 (51%)
Frame 52 (52%)
Frame 53 (53%)
Frame 54 (54%)
Frame 55 (55%)
Frame 56 (56%)
Frame 57 (57%)
Frame 58 (58%)
Frame 59 (59%)
Frame 60 (60%)
Frame 61 (61%)
Frame 62 (62%)
Frame 63 (63%)
Frame 64 (64%)
Frame 65 (65%)
Frame 66 (66%)
Frame 67 (67%)
Frame 68 (68%)
Frame 69 (69%)
Frame 70 (70%)
Frame 71 (71%)
Frame 72 (72%)
Frame 73 (73%)
Frame 74 (74%)
Frame 75 (75%)
Frame 76 (76%)
Frame 77 (77%)
Frame 78 (78%)
Frame 79 (79%)
Frame 80 (80%)
Frame 81 (81%)
Frame 82 (82%)
Frame 83 (83%)
Frame 84 (84%)
Frame 85 (85%)
Frame 86 (86%)
Frame 87 (87%)
Frame 88 (88%)
Frame 89 (89%)
Frame 90 (90%)
Frame 91 (91%)
Frame 92 (92%)
Frame 93 (93%)
Frame 94 (94%)
Frame 95 (95%)
Frame 96 (96%)
Frame 97 (97%)
Frame 98 (98%)
Frame 99 (99%)
Frame 100 (100%)
## Finalizing encoding... done!
```

&lt;img src="Cours1_files/figure-html/unnamed-chunk-18-1.gif" style="display: block; margin: auto;" /&gt;

---
# Visualization using shiny apps

Examples:

- Models used by the united nation to predict demography: [&lt;ru-blockquote&gt; here &lt;/ru-blockquote&gt;](https://bayespop.shinyapps.io/wpp2019explorer/)

- An online application to predict covid19 increase made by Prof. Marc Lavielle in France: [&lt;ru-blockquote&gt; here  &lt;/ru-blockquote&gt;](http://shiny.webpopix.org/covidix/app3/)


--

As you can see, these are great tools for your professional life.

---
# Visualization: ggplot2

In this class we use the package `ggplot2` (implementation by Hadley Wickam). 

--

A `ggplot2` object will have the following elements.footnote[This source explains it well: http://www.john-ros.com/]:

- `data` the data frame holding the data to be plotted.

- `aes` defines the mapping between variables to their visualization.

- `geoms` are the objects/shapes you add as layers to your graph.

- `stats` are statistical transformations when you are not plotting the raw data, such as the mean or confidence intervals.


---
# Histogram

- Visualization of a quantitative variable: histogram


```r
library(ggplot2)
ggplot(ozone, aes(x = maxO3)) +  
  geom_histogram(bins = 10, na.rm = TRUE)
```

&lt;img src="Cours1_files/figure-html/unnamed-chunk-19-1.png" style="display: block; margin: auto;" /&gt;


---
# Histogram with options

- Visualization of a quantitative variable: histogram


```r
# library(ggplot2) # you call it only once
ggplot(ozone, aes(x = maxO3)) +  
  geom_histogram(bins = 10, # important parameter!
                 alpha = 0.5, # transparency
                 color = "blue", #border
                 fill = "pink", # color to fill
                 na.rm = TRUE) + # do the plot ignoring NAs
  theme_bw() # you can look for different themes
```

&lt;img src="Cours1_files/figure-html/unnamed-chunk-20-1.png" style="display: block; margin: auto;" /&gt;


You can find a recap of all the possibilities [&lt;ru-blockquote&gt; here &lt;/ru-blockquote&gt;](https://rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf).
---

# Barplot
- Visualisation of a categorical variable: barplot


```r
ggplot(ozone, aes(x = WindDirection)) +  
  geom_bar(stat = "count", # note the difference!
                 alpha = 0.5, # transparency
                 color = "cyan",
                 fill = "blue") 
```

&lt;img src="Cours1_files/figure-html/unnamed-chunk-21-1.png" style="display: block; margin: auto;" /&gt;

---
# Boxplot

A univariate boxplot helps to highlights outliers.


```r
ggplot(ozone, aes(y = T12)) +  
  geom_boxplot(outlier.color = "red") +
  theme_bw()
```

&lt;img src="Cours1_files/figure-html/unnamed-chunk-22-1.png" style="display: block; margin: auto;" /&gt;


---


# Summarizing data: one variable

Let's pause and look at what we saw.

--

- Statistic for a quantitative variable

  *Quartiles, percentile, mean, median, range, variance, standard deviation*

--

- Statistics for a categorical variable: 

  *Frequency*

--

- Plots
  - *Quantitative*: boxplot and histogram
  - *Qualitative*: barplot
  
--

üí™ Never forget that `R` has a very active community that will (almost) always have a solution to your problem. When you don't understand an error message, copy paste your error message in a web browser and you will find a solution. 

--

Now we would like to analyze several variables **together**. It is a way to highlight associations between the variables!


---
# Visualization: boxplot

You can observe association between a quantitative and qualitative variable.


```r
ggplot(ozone, aes(x = WindDirection, y = maxO3)) +
  geom_boxplot() + 
  theme_bw()
```

&lt;img src="Cours1_files/figure-html/unnamed-chunk-23-1.png" style="display: block; margin: auto;" /&gt;
---
# Visualization: violin

You can choose many other representations, for example violin plots and superposition of your real data points.


```r
ggplot(ozone, aes(x = WindDirection, y =  maxO3, color = T12)) +
  geom_violin() + 
  geom_jitter(alpha = 0.6, width = 0.1)+
  theme_bw()
```

&lt;img src="Cours1_files/figure-html/unnamed-chunk-24-1.png" style="display: block; margin: auto;" /&gt;

---
# Visualization: scatter plot


```r
ggplot(ozone, aes(x = T12, y = T15)) +
  geom_point() + 
  theme_bw()
```

&lt;img src="Cours1_files/figure-html/unnamed-chunk-25-1.png" style="display: block; margin: auto;" /&gt;

Beyond visualization, you all now a numerical indicator that is usually used to characterize the association between two variables ‚ùì
---

# Bivariate analysis

## Correlation coefficient

- Very popular metric
- Useful but contains limits
- The Pearson coefficient is the most used

--

The correlation coefficient between two variables `\(X_1\)` and `\(X_2\)` (for example `T12` and `T15`):
 

`$$\rho_{X_1, X_2}=\frac{\overline{X_1 X_2}- \bar{X_1} \bar{X_2}}{\sigma_{X_1} \sigma_{X_2}}$$`

*where `\(\sigma_{X_i}\)` is the empirical standard deviation of `\(X_i\)`*

--

- `\(\rho_{X_1, X_2} = 1\)` or `\(-1\)`: implies that a linear equation describes the relationship between `\(Z\)` and `\(Y\)` perfectly

- `\(\rho_{X_1, X_2} = 0\)`: no linear relationship between `\(X_1\)` and `\(X_2\)` (‚ö†Ô∏è which is different as saying no relation at all!)


---
# Correlation (1)

## Application in `R` 

We can observe the Pearson correlation between temperature at 12pm and 3pm. 


```r
cor(ozone$T12, ozone$T15, method = "pearson", use = "complete.obs")
```

```
## [1] 0.9476315
```


As expected it shows a high correlation coefficient. We can observe the data to see if it seems coherent. 

--

&lt;img src="Cours1_files/figure-html/unnamed-chunk-27-1.png" style="display: block; margin: auto;" /&gt;

Does the linearity seems to be a good hypothesis for these data?

---

# Correlation (2)

## An apparently simple example

We create a function that simulates two vectors from a Gaussian distribution (mean being 0, and standard deviation being 1) of size `\(n\)`. We first choose `\(n =2\)`, then we do it up to `\(200\)`. We compute the correlation coefficient between each new sampling.

--

&lt;img src="Cours1_files/figure-html/unnamed-chunk-28-1.png" style="display: block; margin: auto;" /&gt;

Comment. What should we do?


---
# Correlation (3)

You can test if your correlation coefficient is meaningful (statistically speaking).

--
First we do this with only 5 observations:

```
## 
## 	Pearson's product-moment correlation
## 
## data:  x1 and x2
## t = 0.792, df = 3, p-value = 0.4862
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.7367073  0.9496858
## sample estimates:
##     cor 
## 0.41585
```

What can we conclude?

--

Don't worry if you don't understand how it works for now, we will come back to this later ‚úÖ

---
# Correlation (4)
## Test with a bigger data set

We repeat the previous test with 10000 observations:


```
## 
## 	Pearson's product-moment correlation
## 
## data:  x1 and x2
## t = 0.3074, df = 9998, p-value = 0.7585
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.01652678  0.02267299
## sample estimates:
##         cor 
## 0.003074284
```

And now?

---
# Correlation (5)

Back to our `ozone` example:


```r
res &lt;- cor.test(ozone$T12, ozone$T15, method = "pearson", use = "complete.obs")
res
```

```
## 
## 	Pearson's product-moment correlation
## 
## data:  ozone$T12 and ozone$T15
## t = 23.552, df = 63, p-value &lt; 0.00000000000000022
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.9152771 0.9678377
## sample estimates:
##       cor 
## 0.9476315
```

What can we conclude?


‚ö†Ô∏è
&gt;In general always associate a numerical indicator with a graphical display

---
# Correlation only reflects linear relationship!

Be careful with correlation. For example all the following data have same mean, sd, and correlation coefficient! (package `datasauRus`)





.center[![Gapminder](./animated_plot/ex_gganimate.gif)]

---

# Correlation is not causation


This credo is constantly repeated, but still it remains very important to understand that __an association in data does not imply a causation__. 


Correlation is one type of association between data. As long as you only observe phenomenon, you can hardly conclude on causation until you perform experiments.

--

This funny website proposes a lot of funny associations:


&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="./img/spurious-correlation.png" alt="From http://tylervigen.com/spurious-correlations" width="60%" /&gt;
&lt;p class="caption"&gt;From http://tylervigen.com/spurious-correlations&lt;/p&gt;
&lt;/div&gt;

---
# Another example

- Sleeping with shoes and headache can show a really strong correlation!

&lt;img src="./img/shoes.png" width="60%" style="display: block; margin: auto;" /&gt;


--

- Do umbrellas cause car accidents?

--


‚ö†Ô∏è Unobserved confounders makes it impossible to separate correlation and causality when correlated to both the outcome and the treatment.


---

# An apparently simple conclusion

Let's have a look to a well-know paradox! üïµ

--


Covid-19 case fatality rates between China and Italy: 44 672 cases from China with early reports from Italy (9th March).

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="./img/italy_china.png" alt="Screenshot from J. von K√ºgelgen et al., 2020" width="35%" /&gt;
&lt;p class="caption"&gt;Screenshot from J. von K√ºgelgen et al., 2020&lt;/p&gt;
&lt;/div&gt;

What do you conclude?


---
# A paradox?

The same data can be represented with age strata.

&lt;div class="figure"&gt;
&lt;img src="./img/italy_china_age.png" alt="Screenshot from J. von K√ºgelgen et al., 2020" width="80%" /&gt;
&lt;p class="caption"&gt;Screenshot from J. von K√ºgelgen et al., 2020&lt;/p&gt;
&lt;/div&gt;

What do you conclude from this graph? 

---
# The Simpson paradox

## Only seeing can even lead to wrong conclusions! ‚ö†Ô∏è


&lt;div class="figure"&gt;
&lt;img src="./img/italy_china_case.png" alt="Screenshot from J. von K√ºgelgen et al., 2020" width="60%" /&gt;
&lt;p class="caption"&gt;Screenshot from J. von K√ºgelgen et al., 2020&lt;/p&gt;
&lt;/div&gt;

Complete article: *Simpson's paradox in Covid-19 case fatality rates: a mediation analysis of age-related causal effects* from Julius von K√ºgelgen, Luigi Gresele, Bernhard Sch√∂lkopf

---
# Another example: effect of class size (1)

Imagine we want to measure the effect of class size on the results of children.

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="./img/histogram_class_size.png" alt="DEPP" width="50%" /&gt;
&lt;p class="caption"&gt;DEPP&lt;/p&gt;
&lt;/div&gt;

What do you suggest to measure the effect?

---
# Another example: effect of class size (2)

.pull-left[
&lt;img src="./img/naive_class.png" width="150%" style="display: block; margin: auto;" /&gt;

The difference is statistically significant.
]

--

.pull-right[

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="./img/histogram_class_size_with_categ.png" alt="DEPP" width="180%" /&gt;
&lt;p class="caption"&gt;DEPP&lt;/p&gt;
&lt;/div&gt;
]

---
# Break

We can pause and resume what we saw.

--

- Correlation coefficient is an interesting tool, 

- ... but it can not resume all type of association and it has to be significant!

- Correlation is an association between data, it does not imply a causal link.

- Paradox can be hidden in the data, the Simpson paradox is a famous one.

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="./img/simpson_paradox.jpg" alt="Simpson paradox made simple" width="40%" /&gt;
&lt;p class="caption"&gt;Simpson paradox made simple&lt;/p&gt;
&lt;/div&gt;


--

‚û°Ô∏è The next part of the class is about statistical test, and how to get an information from a limited sample.

---
# Statistical tests

With the correlation coefficient, we introduced the concept of a statistical test. The typical question to answer is:
How we can draw conclusions or make decisions based on finite samples of data?

--

A wide variety of usage:

- Clinical trials and efficacy;

- Economic experiments;

- Screening genetic variants for associations with a phenotype, and many others.

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="./img/test.png" alt="Credits: Modern Statistics for Modern Biology, Chap 6., Susan Holmes" width="20%" /&gt;
&lt;p class="caption"&gt;Credits: Modern Statistics for Modern Biology, Chap 6., Susan Holmes&lt;/p&gt;
&lt;/div&gt;

---
# Confidence interval (CI)

.pull-left[

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="./img/confidence_interval.png" alt="Credits: xkcd.com" width="50%" /&gt;
&lt;p class="caption"&gt;Credits: xkcd.com&lt;/p&gt;
&lt;/div&gt;

]
.pull-right[

* In real life we only get to take ***one*** sample from the population.

* Also, we obviously don't know the true population parameter, that's what we are interested in!

* What can we do in practice?

]

--


Even unobserved, we know that the sampling distribution does exist (or we put hypothesis on it), and with assumptions, we know how it behaves!

---
# Point estimates versus CI

Until now we have only estimated *point estimates* from our samples: for example sample mean.

--

We saw a glimpse of what is a confidence interval with the correlation test. But what does this mean exactly?

--

Rather that a point estimate, we could give a range of plausible values for the parameters we are interested in.


--

This is what a **confidence interval** (CI) provides.

--

With a confidence interval comes a confidence *level*, usually it is 95%.

&gt; *Interpreation* Imagine we do 100 times the experiment and construct a confidence interval. 95 out of 100 of the confidence intervals constructed would contain the good value.

--

There are several ways to compute a CI, depending on the question asked.

---
# Intuition of the notion

We can simulate data of a somnifere on the average sleeping time. Here you can see the results of a small study with 30 people included.

&lt;img src="Cours1_files/figure-html/unnamed-chunk-45-1.png" style="display: block; margin: auto;" /&gt;

What can you conclude?

---
# The more data, the bigger the certainty

Here we gathered 100 patients in the study.

&lt;img src="Cours1_files/figure-html/unnamed-chunk-46-1.png" style="display: block; margin: auto;" /&gt;
---

#  In practice


```r
t.test(control, sample2)
```

```
## 
## 	Welch Two Sample t-test
## 
## data:  control and sample2
## t = -2.8553, df = 150.78, p-value = 0.004906
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -1.1111202 -0.2022729
## sample estimates:
## mean of x mean of y 
##  7.026535  7.683232
```
--

The command is simple, but then you have to precisely know where to read the results (confidence interval, p-value, hypothesis meaning, and so on).

Also, be careful on the fact that it requires hypothesis on your distribution.

---
# With ozone data set




```r
t.test(ozone$maxO3, conf.level = 0.95)$conf.int
```

```
## [1] 85.37665 97.10252
## attr(,"conf.level")
## [1] 0.95
```


&lt;img src="Cours1_files/figure-html/unnamed-chunk-49-1.png" style="display: block; margin: auto;" /&gt;

---
# Conclusion

Today you have seen how to perform a simple data exploration with `R` and that being cautious with indicators is important.

--

By next class you can train on any data set to perform a simple data analysis. You can find some more (related to economy) on the github `experimentdatar` repository.

--

Next class will be about Principal Component Analysis (PCA), clustering and dimension reduction.

---

# Ressources

Plenty of ressources are available online on data exploration and statistics with `R`. And we gathered some for you here:

**Basics**

- [&lt;ru-blockquote&gt;
TedX on data visualisation
&lt;/ru-blockquote&gt;](https://www.ted.com/talks/david_mccandless_the_beauty_of_data_visualization?language=fr)

- [&lt;ru-blockquote&gt;
Starting with Rstudio, advanced statistics &lt;/ru-blockquote&gt;](http://larmarange.github.io/analyse-R/)

**Funny**

- [&lt;ru-blockquote&gt; To play down statistics: *La statistique expliqu√©e √† mon chat* &lt;/ru-blockquote&gt;](https://www.youtube.com/channel/UCWty1tzwZW_ZNSp5GVGteaA/featured)


**Advanced**

- [&lt;ru-blockquote&gt; Susan Holmes' book "Modern Statistics for Modern Biology" &lt;/ru-blockquote&gt;](http://web.stanford.edu/class/bios221/book/)
- [&lt;ru-blockquote&gt; Introduction to econometrics with R (SciencesPo)&lt;/ru-blockquote&gt;](https://scpoecon.github.io/ScPoEconometrics/index.html) 

---
# Credits

This class was made with inspiration from:

- [&lt;ru-blockquote&gt; Susan Holmes' book "Modern Statistics for Modern Biology" &lt;/ru-blockquote&gt;](http://web.stanford.edu/class/bios221/book/)

- [&lt;ru-blockquote&gt; Introduction to econometrics with R (SciencesPo)&lt;/ru-blockquote&gt;](https://scpoecon.github.io/ScPoEconometrics/index.html) 

- And datanovia website for the animated plots


Thanks to all of them - and others - for open science.

---
Next slides are additional ones, it completes the statistical tests part in more details.

---
# From CI to hypothesis testing

Just like confidence intervals, hypothesis tests are used to make claims about a population based on the information from a sample.

--

A hypothesis test consists of a test between two competing hypothesis about a parameter. 

--

&gt;For example the average income for women and men measured in one sample is different. Is the difference significant? ü§î

--

The usual framework you will find in books is:

- The null hypothesis usually states no difference, and we denote it `\(H_{0}\)` (in our little example it would mean that men and women have same average income)

- The alternative hypothesis states that it is different, and we denote it `\(H_{1}\)`

--

Let's take a simple - but detailed - example to understand the principle: coin tossing

---
# An example: coin tossing

Imagine I simulate a coin with a probability of head `\(p\)` (this is something you can easily do in `R`). 

--

You want to know if the coin is fair ( `\(p = 0.5\)` ). What do you do? 

--

Yes, you start flipping the coin. Results type are:


```
## [1] "H" "T" "H" "T" "T" "H"
```

--

You do it a lot, for example 100 time. If the coin is fair, you would expect half of the time to get heads. We can compute how many heads you obtained on the 100 flips.


```r
table(coinFlips)
```

```
## coinFlips
##  H  T 
## 60 40
```

What do you do? Continue up to 1000 times? Stop and conclude? Was it bad luck?
---
# How probable was this realisation?

The number of heads obtained in 100 independent tosses of a coin is:

`$$P(K=k \mid 100, p)=\left(\begin{array}{c}100 \\ k\end{array}\right) p^{k}(1-p)^{100-k}$$`

Where `\(p\)` is the probability of heads.

--

&gt;Notations' tips: 
- The first term reads as: the probability that the observed value for `\(K\)` is 
`\(k\)`, given the values of `\(n\)` and `\(p\)` ( `\(p\)` is the parameter of our problem).
- The big `\(K\)` is all the possible values we can have (here from 0 to 100), and `\(k\)` is the value observed. Statisticians usually write the difference.



---


We implement the previous equation. Note that the binomial is already implemented in `R` with `dbinom`:



&lt;img src="Cours1_files/figure-html/unnamed-chunk-53-1.png" style="display: block; margin: auto;" /&gt;


What is the most probable value?
To what corresponds the vertical line?

--

But at which point could we consider this was not just bad luck?

---
# Formalization

Statisticians divide the set of all possible `\(k\)` (0 to 100) in complementary regions: a rejection region and a region of no rejection.

--

The common threshold is `\(\alpha = 0.05\)` meaning that if the observed `\(k\)` is in a region which probability is lower than 0.05 then the null-hypothesis is rejected.

--

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="./img/threshold.png" alt="Credits: xkcd cartoons" width="25%" /&gt;
&lt;p class="caption"&gt;Credits: xkcd cartoons&lt;/p&gt;
&lt;/div&gt;


&gt;‚ö†Ô∏è Remember that the `\(\alpha = 0.05\)` rule is a convention!

---
# Visualization of the `\(\alpha\)`







&lt;img src="Cours1_files/figure-html/unnamed-chunk-56-1.png" style="display: block; margin: auto;" /&gt;

What do you conclude? ü§î

---
# Using implemented function

We state the null-hypothesis `\(\mathbb{H}_0:  p=0.5\)`. 

In our example we observe 60 heads. We can use the implemented function:


```r
binom.test(x = numHeads, n = numFlips, p = 0.5)
```

```
## 
## 	Exact binomial test
## 
## data:  numHeads and numFlips
## number of successes = 60, number of trials = 100, p-value = 0.05689
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.4972092 0.6967052
## sample estimates:
## probability of success 
##                    0.6
```

We conclude that the coin is fair, but you can observe that it depends on the confidence level you fixed!

---
# Confidence interval for a mean

For a relative big (&gt;30) sample, the central limit theorem guarantees that the confidence interval is this one:

`$$\left[\bar{x}-\frac{\hat{\sigma}}{\sqrt{n}} \times t_{1-\alpha / 2}(n-1) ; \bar{x}+\frac{\hat{\sigma}}{\sqrt{n}} \times t_{1-\alpha / 2}(n-1)\right]$$`
With `\(n\)` the sample size, `\(\bar{x}\)` the empirical mean, `\(\hat{\sigma}\)` the empirical standard deviation, and `\(t_{1-\alpha / 2}\)` a parameter from the Student law (beyond the scope of the class).

.pull-left[
&lt;img src="Cours1_files/figure-html/unnamed-chunk-58-1.png" style="display: block; margin: auto;" /&gt;
]

.pull-right[

```r
t.test(ozone$maxO3, conf.level=0.95)$conf.int
```

```
## [1] 85.37665 97.10252
## attr(,"conf.level")
## [1] 0.95
```
]

---
# p-value


&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="./img/pvalue.png" alt="https://towardsdatascience.com/wait-so-whats-a-p-value-6fc50f362df1" width="50%" /&gt;
&lt;p class="caption"&gt;https://towardsdatascience.com/wait-so-whats-a-p-value-6fc50f362df1&lt;/p&gt;
&lt;/div&gt;

--

&gt;**Rigorous definition**

&gt;Consider that null-hypothesis is true. The ***p-value*** is the probability of observing a test statistic more extreme than the one we obtained.

&gt;If the p-value falls below the cutoff `\(\alpha\)`, we reject the null hypothesis on the grounds that what we observe is too unlikely to happen under the Null

‚ö†Ô∏è Be careful with what is called the p-value hacking and multiple testing.


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create();
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
